
反射原理
---

### 目录

1. JVM是如何实现反射的
    - 本地实现
    - 动态实现
2. 反射的性能开销体现在哪里
3. 优化反射性能开销

## 1. JVM如何实现反射的?

直接上例子
```java
public class Solution {

    public static void show(int i) {
        new Exception("#" + i).printStackTrace();
    }

    public static void main(String[] args) throws Exception {
        Class<?> clazz = Class.forName("Solution");
        Method method = clazz.getMethod("show", int.class);
        method.invoke(null, 0);
    }

}
```

上面的代码中测试了Method.invoke来执行反射方法调用,为了方便查看调用了哪些类,我们打印了show方法的栈轨迹.输出如下:

```java
java.lang.Exception: #0
	at Solution.show(Solution.java:15)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at Solution.main(Solution.java:21)
```

首先是来到Method的invoke方法,来看看实现

```java
public final class Method extends Executable {
  ...
  public Object invoke(Object obj, Object... args) throws ... {
    ... // 权限检查
    MethodAccessor ma = methodAccessor;
    if (ma == null) {
      ma = acquireMethodAccessor();
    }
    return ma.invoke(obj, args);
  }
}

```

可以看到,实际上它是委派给了MethodAccessor来处理,MethodAccessor是一个接口,它有2个已有的具体实现: 一个是通过本地方法(NativeMethodAccessorImpl)来实现反射,简称**本地实现**;另一个则使用了委派模式(DelegatingMethodAccessorImpl),简称**委派实现**.

其实MethodAccessor实例是在ReflectionFactory中创建的

```java
public class ReflectionFactory {

    private static boolean initted = false;
    private static final ReflectionFactory soleInstance = new ReflectionFactory();
    // Provides access to package-private mechanisms in java.lang.reflect
    private static volatile LangReflectAccess langReflectAccess;

    /* Method for static class initializer <clinit>, or null */
    private static volatile Method hasStaticInitializerMethod;

    //
    // "Inflation" mechanism. Loading bytecodes to implement
    // Method.invoke() and Constructor.newInstance() currently costs
    // 3-4x more than an invocation via native code for the first
    // invocation (though subsequent invocations have been benchmarked
    // to be over 20x faster). Unfortunately this cost increases
    // startup time for certain applications that use reflection
    // intensively (but only once per class) to bootstrap themselves.
    // To avoid this penalty we reuse the existing JVM entry points
    // for the first few invocations of Methods and Constructors and
    // then switch to the bytecode-based implementations.
    //
    // Package-private to be accessible to NativeMethodAccessorImpl
    // and NativeConstructorAccessorImpl
    //注意: 下面2个变量是静态的
    private static boolean noInflation        = false;
    private static int     inflationThreshold = 15;
    
    //...
    public MethodAccessor newMethodAccessor(Method method) {
        checkInitted();

        if (Reflection.isCallerSensitive(method)) {
            Method altMethod = findMethodForReflection(method);
            if (altMethod != null) {
                method = altMethod;
            }
        }

        // use the root Method that will not cache caller class
        Method root = langReflectAccess.getRoot(method);
        if (root != null) {
            method = root;
        }

        // 这里需要注意一点，VMAnonymousClass 并不是指匿名内部类
        // 它可以看做是 JVM 里面的一个模板机制
        if (noInflation && !ReflectUtil.isVMAnonymousClass(method.getDeclaringClass())) {
            return new MethodAccessorGenerator().
                generateMethod(method.getDeclaringClass(),
                               method.getName(),
                               method.getParameterTypes(),
                               method.getReturnType(),
                               method.getExceptionTypes(),
                               method.getModifiers());
        } else {
            NativeMethodAccessorImpl acc =
                new NativeMethodAccessorImpl(method);
            DelegatingMethodAccessorImpl res =
                new DelegatingMethodAccessorImpl(acc);
            acc.setParent(res);
            return res;
        }
    }
}    

```
在第一次调用反射的时候,noInflation是为false的,这时就会生成一个委派实现,而委派实现的具体实现便是一个本地实现.本地实现: 当进入Java虚拟机内部之后,我们便拥有了Method实例所指向方法的具体地址.这时候,反射调用其实就是将传入的参数准备好,然后调用进去目标方法即可.

有个疑问? 直接交给本地实现不就可以了吗,为啥还需要一个委派实现作为中间层呢? 其实,Java的反射调用机制还设立了另一种动态生成字节码的实现(简称**动态实现**),直接使用invoke指令来调用目标方法,之所以采用委派实现,就是为了能够在本地实现和动态实现中切换.

上面的源码注释中已经说了,动态实现和本地实现相比,其运行效率要快上20倍.这是因为动态实现无需经过Java到C++,再到Java的切换,但由于生成字节码十分耗时,仅调用一次的话,反而是本地实现要快上3到4倍.

考虑到许多反射调用仅会执行一次,Java虚拟机设置了一个阈值15,当某个反射调用的次数在15之下时,采用本地实现;当达到15时,便开始动态生成字节码,并将委派实现的委派对象切换到动态实现,这个过程我们称之为Inflation.

那么inflationThreshold这个阈值15是在哪里判断的?

```java
/** Used only for the first few invocations of a Method; afterward,
    switches to bytecode-based implementation 
    
    前面几次反射调用时会使用本地实现,达到阈值之后会生成字节码,然后就会切换到基于字节码的动态实现.
*/
class NativeMethodAccessorImpl extends MethodAccessorImpl {
    private final Method method;
    private DelegatingMethodAccessorImpl parent;
    private int numInvocations;

    NativeMethodAccessorImpl(Method method) {
        this.method = method;
    }

    public Object invoke(Object obj, Object[] args)
        throws IllegalArgumentException, InvocationTargetException
    {
        // We can't inflate methods belonging to vm-anonymous classes because
        // that kind of class can't be referred to by name, hence can't be
        // found from the generated bytecode.
        if (++numInvocations > ReflectionFactory.inflationThreshold()
                && !ReflectUtil.isVMAnonymousClass(method.getDeclaringClass())) {
            MethodAccessorImpl acc = (MethodAccessorImpl)
                new MethodAccessorGenerator().
                    generateMethod(method.getDeclaringClass(),
                                   method.getName(),
                                   method.getParameterTypes(),
                                   method.getReturnType(),
                                   method.getExceptionTypes(),
                                   method.getModifiers());
            parent.setDelegate(acc);
        }

        return invoke0(method, obj, args);
    }

    void setParent(DelegatingMethodAccessorImpl parent) {
        this.parent = parent;
    }

    private static native Object invoke0(Method m, Object obj, Object[] args);
}
```

是在本地实现NativeMethodAccessorImpl中,每次NativeMethodAccessorImpl的invoke方法被调用,都会增加一次计时器.并且每次都会判断一下,是否超过阈值,超过则调用MethodAccessorGenerator.generateMethod()来生成Java版的MethodAccessor的实现类,并且改变DelegatingMethodAccessorImpl所引用的MethodAccessor为Java版.后面再使用的时候,就是Java版的MethodAccessor实现了.

从上面的信息可以推断出,反射调用的第一次和第十六次是最耗时的(初始化NativeMethodAccessorImpl和字节码动态生成MethodAccessorImpl).初始化是无法避免的,而Native方式的初始化会更快,因此前几次的调用会采用Native方法.

随着调用次数的增加,每次反射都使用JNI跨越Native边界会对优化有阻碍作用,相对来说使用拼装出的字节码可以直接以Java调用的形式实现反射,发挥了JIT优化的作用,避免了JNI为了维护OopMap(HotSpot用来实现准确式GC的数据结构)进行封装/解封装的性能损耗.因此在已经创建了MethodAccessor的情况下,使用Java版本的实现会比Native版本更快,所以当调用次数到达一定次数后,会切换成Java实现的版本,来优化未来可能更频繁的反射调用.

JVM如何实现反射 小结:

在默认情况下,方法的反射调用为委派实现,委派给本地实现来进行方法调用.在调用超过15次之后,委派实现便会将委派对象切换至动态实现,这个动态实现的字节码是自动生成的,它将直接使用invoke指令来调用目标方法.

反射调用的Inflation机制是可以通过参数(-Dsun.reflect.noInflation=true)来关闭的,关闭之后,在反射调用的一开始就会直接生成动态实现,而不会使用委派实现或者本地实现.

## 2. 反射的性能开销体现在哪里?

在上面的例子中,我们先后使用了`Class.forName`,`Class.getMethod`以及`Method.invoke`三个操作.其中Class.forName会调用本地方法,Class.getMethod则会遍历该类的公有方法.如果没有匹配到,它还将遍历父类的公有方法,可想而知,这两个操作都是非常耗时的.

需要注意,以getMethod为代表的查找方法操作,会返回查找得到结果的一份拷贝.因此,我们应当避免在热点代码中使用返回Method数组的getMethods或者getDeclaredMethods方法,以减少不必要的堆空间消耗.

在实践中,我们往往会在应用程序中缓存Class.forName和Class.getMethod的结果.因此,下面我们就只关注反射调用本身的性能开销.

```java
public class ReflectDemo {

    public void doSth(int i) {

    }

    public static void main(String[] args) throws Exception {
        Class<?> clazz = ReflectDemo.class;
        Constructor constructor = clazz.getConstructor();
        Object object = constructor.newInstance();
        Method method = clazz.getMethod("doSth", int.class);

        ReflectDemo demo = new ReflectDemo();

        long current = System.currentTimeMillis();
        for (int i = 1; i <= 2_000_000_000; i++) {
            if (i % 100_000_000 == 0) {
                long temp = System.currentTimeMillis();
                System.out.println(temp - current);
                current = temp;
            }
            // 直接调用
            demo.doSth(2333);
            // 反射调用
            // method.invoke(object, 2333);
        }
    }
}
```

取最后五个记录的平均值,作为预热后的峰值性能,一亿次的直接调用耗时为91.6ms(在我这台电脑上),然后把91.6ms作为基准值. 改为反射调用后,测得的结果是281.6ms,约为基准值的3.07倍.

除了反射调用外,还额外做了两个操作:

- 由于Method.invoke是一个变长参数方法,在字节码层面它的最后一个参数会是Object数组.Java编译器会在方法调用处生成一个长度为传入参数数量的Object数组,并将传入参数一一存储进该数组中.
- 由于Object数组不能存储基本类型,Java编译器会将传入的基本数据类型进行自动装箱.

这两个操作除了带来额外的性能开销外,还可能占用堆内存,使得GC更加频繁.

如何消除这部分开销呢?

关于第二个自动装箱,Java缓存了[-128,127]中所有整数所对应的Integer对象,当需要自动装箱的整数在这个范围内时,便返回缓存的Integer,否则需要新建一个Integer对象.因此我们可以使用已经缓存的Integer对象或者扩大Integer对象.

再来看看因变长参数生成的Object数组,既然每个反射调用对应的参数个数是固定的,那么我们可以选择在循环外新建一个Object数组,设置好参数并直接交给反射调用:

```java
public class ReflectDemo {

    public void doSth(int i) {

    }

    public static void main(String[] args) throws Exception {
        Class<?> clazz = ReflectDemo.class;
        Constructor constructor = clazz.getConstructor();
        Object object = constructor.newInstance();
        Method method = clazz.getMethod("doSth", int.class);

        // 在循环外构造参数数组
        Object[] arg = new Object[1];
        arg[0] = 2333;

        long current = System.currentTimeMillis();
        for (int i = 1; i <= 2_000_000_000; i++) {
            if (i % 100_000_000 == 0) {
                long temp = System.currentTimeMillis();
                System.out.println(temp - current);
                current = temp;
            }
            // 反射调用
            method.invoke(object, arg);
        }
    }
}
```

测试的结果反而更加糟糕了,为基准值的3.3倍.在解决了自动装箱之后查看运行时的GC状况时(使用 -Xlog:gc 参数，打印 GC 信息),你会发现这段程序并不会触发GC.其原因在于,原本的反射调用被内联了,从而使得即时编译器中的逃逸分析将原本新建的Object数组判断为不逃逸的对象.如果一个对象不逃逸,那么即时编译器可以选择栈分配甚至是虚拟分配,也就是不占用堆空间.如果在循环外新建数组,即时编译器无法确定这个数组会不会中途被更改,因此无法优化掉访问数组的操作,可谓是得不偿失.

前面我们提到,可以关闭反射调用的Inflation机制,从而取消委派实现,直接使用动态实现.此外,每次反射调用都会检查目标方法权限,而这个检查同样可以在Java代码里关闭,在关闭了权限检查机制之后,代码如下:

```java
public class ReflectDemo {

    public void doSth(int i) {

    }

    public static void main(String[] args) throws Exception {
        Class<?> clazz = ReflectDemo.class;
        Constructor constructor = clazz.getConstructor();
        Object object = constructor.newInstance();
        Method method = clazz.getMethod("doSth", int.class);
        method.setAccessible(true); // 关闭权限检查

        long current = System.currentTimeMillis();
        for (int i = 1; i <= 2_000_000_000; i++) {
            if (i % 100_000_000 == 0) {
                long temp = System.currentTimeMillis();
                System.out.println(temp - current);
                current = temp;
            }
            // 反射调用
            method.invoke(object, 23);
        }
    }
}
```

测试结果约为基准值的2.2倍.这个例子中之所以反射调用变快了,是因为即时编译器的方法内联.在关闭了Inflation的情况下,内联的瓶颈在于Method.invoke方法中对MethodAccessor.invoke 方法的调用.

在生产环境中,我们往往拥有多个不同的反射调用,对应多个GeneratedMethodAccessor,也就是动态实现.由于Java虚拟机的关于上述调用点的类型profile(注: 对于invokevirtual或者invokeinterface,Java虚拟机会记录调用者的具体类型,我们称之为profile)无法同时记录这么多个类,因此可能造成所测试的反射调用没有被内联的情况.

```java
public class ReflectDemo {

    public void doSth(int i) {

    }

    public static void main(String[] args) throws Exception {
        Class<?> clazz = ReflectDemo.class;
        Constructor constructor = clazz.getConstructor();
        Object object = constructor.newInstance();
        Method method = clazz.getMethod("doSth", int.class);
        method.setAccessible(true); // 关闭权限检查

        polluteProfile();

        long current = System.currentTimeMillis();
        for (int i = 1; i <= 2_000_000_000; i++) {
            if (i % 100_000_000 == 0) {
                long temp = System.currentTimeMillis();
                System.out.println(temp - current);
                current = temp;
            }
            // 反射调用
            method.invoke(object, 23);
        }
    }

    public static void polluteProfile() throws Exception {
        Class<?> clazz = ReflectDemo.class;
        Constructor constructor = clazz.getConstructor();
        Object object = constructor.newInstance();
        Method method1 = clazz.getMethod("target1", int.class);
        Method method2 = clazz.getMethod("target2", int.class);
        for (int i = 0; i < 2000; i++) {
            method1.invoke(object, 0);
            method2.invoke(object, 0);
        }
    }

    public void target1(int i) {

    }

    public void target2(int i) {

    }
}
```

这时的测试结果为基准值的7.2倍.也就是说,只要耽搁了Method.invoke方法的类型profile,性能开销便从2.2上升到7.2倍.之所以这么慢,除了没有方法内联之外,另一个原因是逃逸分析不再生效.这个时候便可以在循环外构建参数数组,并直接传递给反射调用,这样子测的结果为基准值的5.8倍. 

除此之外,我们还可以提高Java虚拟机关于每个调用能够记录的类型数目(对应虚拟机参数-XX:TypeProfileWidth，默认值为 2，这里设置为 8).

影响反射调用耗时有以下原因:

1. **方法表查找**
2. **构建Object数组以及可能存在的自动装拆箱操作**
3. **运行时权限检查**
4. **可能没有方法内联/逃逸分析**(简单来说就是有没有可能被其他人修改,如果肯定不能,那么就不做逃逸分析,耗时更短)

## 3. 如何优化反射性能开销?

1. **尽量避免反射调用虚方法**
2. **关闭运行时权限检查** : `setAccessible(true);`
3. **可能需要增大基本数据类型对应的包装类缓存**(我们可以将这个缓存的范围扩大至覆盖 128 (对应参数-Djava.lang.Integer.IntegerCache.high=128) )
4. **关闭Inflation机制**(直接动态生成字节码)
5. **提高JVM关于每个调用能够记录的类型数目**(上面文章中的类型profile)

## 参考

- [JVM是如何实现反射的？](https://time.geekbang.org/column/article/12192)
- [Java反射原理简析](http://fanyilun.me/2015/10/29/Java%E5%8F%8D%E5%B0%84%E5%8E%9F%E7%90%86/)
- [深入理解反射](https://github.com/Omooo/Android-Notes/blob/master/blogs/Java/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%8F%8D%E5%B0%84.md)
